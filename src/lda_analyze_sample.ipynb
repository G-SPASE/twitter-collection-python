{
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "import os\n",
      "CORPUS_PATH = os.path.join('data/MalletSampleData', 'austen-brontë-split')\n",
      "filenames = sorted([os.path.join(CORPUS_PATH, fn) for fn in os.listdir(CORPUS_PATH)])"
     ],
     "language": "python",
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "813"
       ],
       "metadata": {}
      }
     ],
     "input": [
      "len(filenames)"
     ],
     "language": "python",
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "['data/MalletSampleData/austen-brontë-split/Austen_Emma0000.txt',\n 'data/MalletSampleData/austen-brontë-split/Austen_Emma0001.txt',\n 'data/MalletSampleData/austen-brontë-split/Austen_Emma0002.txt',\n 'data/MalletSampleData/austen-brontë-split/Austen_Emma0003.txt',\n 'data/MalletSampleData/austen-brontë-split/Austen_Emma0004.txt']"
       ],
       "metadata": {}
      }
     ],
     "input": [
      "filenames[:5]"
     ],
     "language": "python",
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "import numpy as np\n",
      "\n",
      "import itertools, operator, os"
     ],
     "language": "python",
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "def grouper(n, iterable, fillvalue=None):\n",
      "    \"Collect data into fixed-length chunks or blocks\"\n",
      "    \n",
      "    \n",
      "    args = [iter(iterable)] * n\n",
      "    return itertools.zip_longest(*args, fillvalue=fillvalue)"
     ],
     "language": "python",
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "doctopic_triples = []\n",
      "mallet_docnames = []"
     ],
     "language": "python",
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "with open(\"/Users/koitaroh/Documents/GitHub/GeoTweetCollector/data/doc-topics-austen-bronte.tsv\", encoding=\"utf-8\") as f:\n",
      "    f.readline()  # read one line in order to skip the header\n",
      "    \n",
      "    for line in f:\n",
      "        docnum, docname, *values = line.rstrip().split('\\t')\n",
      "        \n",
      "        mallet_docnames.append(docname)\n",
      "        for topic, share in grouper(2, values):\n",
      "            triple = (docname, int(topic), float(share))\n",
      "            doctopic_triples.append(triple)\n",
      "            \n",
      "# sort the triples\n",
      "# triple is (docname, topicnum, share) so sort(key=operator.itemgetter(0,1))\n",
      "# sorts on (docname, topicnum) which is what we want"
     ],
     "language": "python",
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "[('file:/Users/koitaroh/Documents/GitHub/GeoTweetCollector/data/MalletSampleData/austen-brontë-split/Austen_Emma0000.txt',\n  9,\n  0.21125265392781317),\n ('file:/Users/koitaroh/Documents/GitHub/GeoTweetCollector/data/MalletSampleData/austen-brontë-split/Austen_Emma0000.txt',\n  16,\n  0.16878980891719744),\n ('file:/Users/koitaroh/Documents/GitHub/GeoTweetCollector/data/MalletSampleData/austen-brontë-split/Austen_Emma0000.txt',\n  10,\n  0.1305732484076433),\n ('file:/Users/koitaroh/Documents/GitHub/GeoTweetCollector/data/MalletSampleData/austen-brontë-split/Austen_Emma0000.txt',\n  19,\n  0.09447983014861996),\n ('file:/Users/koitaroh/Documents/GitHub/GeoTweetCollector/data/MalletSampleData/austen-brontë-split/Austen_Emma0000.txt',\n  11,\n  0.09235668789808917)]"
       ],
       "metadata": {}
      }
     ],
     "input": [
      "doctopic_triples[:5]"
     ],
     "language": "python",
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "[('file:/Users/koitaroh/Documents/GitHub/GeoTweetCollector/data/MalletSampleData/austen-brontë-split/Austen_Emma0000.txt',\n  0,\n  0.0074309978768577496),\n ('file:/Users/koitaroh/Documents/GitHub/GeoTweetCollector/data/MalletSampleData/austen-brontë-split/Austen_Emma0000.txt',\n  1,\n  0.032908704883227176),\n ('file:/Users/koitaroh/Documents/GitHub/GeoTweetCollector/data/MalletSampleData/austen-brontë-split/Austen_Emma0000.txt',\n  2,\n  0.04777070063694268),\n ('file:/Users/koitaroh/Documents/GitHub/GeoTweetCollector/data/MalletSampleData/austen-brontë-split/Austen_Emma0000.txt',\n  3,\n  0.024416135881104035),\n ('file:/Users/koitaroh/Documents/GitHub/GeoTweetCollector/data/MalletSampleData/austen-brontë-split/Austen_Emma0000.txt',\n  4,\n  0.01167728237791932)]"
       ],
       "metadata": {}
      }
     ],
     "input": [
      "doctopic_triples = sorted(doctopic_triples, key=operator.itemgetter(0,1))\n",
      "doctopic_triples[:5]"
     ],
     "language": "python",
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "['file:/Users/koitaroh/Documents/GitHub/GeoTweetCollector/data/MalletSampleData/austen-brontë-split/Austen_Emma0000.txt',\n 'file:/Users/koitaroh/Documents/GitHub/GeoTweetCollector/data/MalletSampleData/austen-brontë-split/Austen_Emma0001.txt',\n 'file:/Users/koitaroh/Documents/GitHub/GeoTweetCollector/data/MalletSampleData/austen-brontë-split/Austen_Emma0002.txt',\n 'file:/Users/koitaroh/Documents/GitHub/GeoTweetCollector/data/MalletSampleData/austen-brontë-split/Austen_Emma0003.txt',\n 'file:/Users/koitaroh/Documents/GitHub/GeoTweetCollector/data/MalletSampleData/austen-brontë-split/Austen_Emma0004.txt']"
       ],
       "metadata": {}
      }
     ],
     "input": [
      "mallet_docnames = sorted(mallet_docnames)\n",
      "mallet_docnames[:5]"
     ],
     "language": "python",
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "813"
       ],
       "metadata": {}
      }
     ],
     "input": [
      "num_docs = len(mallet_docnames)\n",
      "num_docs"
     ],
     "language": "python",
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "16260"
       ],
       "metadata": {}
      }
     ],
     "input": [
      "len(doctopic_triples)"
     ],
     "language": "python",
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "20"
       ],
       "metadata": {}
      }
     ],
     "input": [
      "num_topics = len(doctopic_triples) // len(mallet_docnames)\n",
      "num_topics"
     ],
     "language": "python",
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "doctopic = np.zeros((num_docs, num_topics))"
     ],
     "language": "python",
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      ""
     ],
     "language": "python"
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "\n",
      "for triple in doctopic_triples:\n",
      "    \n",
      "    docname, topic, share = triple\n",
      "    row_num = mallet_docnames.index(docname)\n",
      "    doctopic[row_num, topic] = share"
     ],
     "language": "python",
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "array([[ 0.007431  ,  0.0329087 ,  0.0477707 ,  0.02441614,  0.01167728,\n         0.03078556,  0.01592357,  0.02016985,  0.01380042,  0.21125265,\n         0.13057325,  0.09235669,  0.02653928,  0.01592357,  0.00955414,\n         0.007431  ,  0.16878981,  0.01380042,  0.02441614,  0.09447983],\n       [ 0.00657895,  0.01184211,  0.09342105,  0.01447368,  0.00921053,\n         0.01710526,  0.03552632,  0.00921053,  0.00921053,  0.09342105,\n         0.03552632,  0.06973684,  0.04605263,  0.11447368,  0.01973684,\n         0.04868421,  0.31710526,  0.01184211,  0.00921053,  0.02763158],\n       [ 0.00605327,  0.02058111,  0.0811138 ,  0.01331719,  0.01331719,\n         0.02300242,  0.02058111,  0.03268765,  0.01089588,  0.16828087,\n         0.05205811,  0.06416465,  0.02300242,  0.08837772,  0.0157385 ,\n         0.00847458,  0.30145278,  0.00605327,  0.01089588,  0.03995157],\n       [ 0.00543478,  0.01847826,  0.04891304,  0.03369565,  0.02065217,\n         0.04673913,  0.025     ,  0.00978261,  0.02065217,  0.25543478,\n         0.08369565,  0.09456522,  0.03369565,  0.01413043,  0.0076087 ,\n         0.0076087 ,  0.21195652,  0.0076087 ,  0.0076087 ,  0.04673913],\n       [ 0.00518672,  0.01556017,  0.08195021,  0.0093361 ,  0.01556017,\n         0.05082988,  0.02178423,  0.0093361 ,  0.01141079,  0.14211618,\n         0.09854772,  0.06120332,  0.03838174,  0.05912863,  0.00726141,\n         0.02593361,  0.26244813,  0.01763485,  0.0093361 ,  0.05705394]])"
       ],
       "metadata": {}
      }
     ],
     "input": [
      "doctopic[:5]"
     ],
     "language": "python",
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "novel_names = []"
     ],
     "language": "python",
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "for fn in filenames:\n",
      "    basename = os.path.basename(fn)\n",
      "    name, ext = os.path.splitext(basename)\n",
      "    name = name.rstrip('0123456789')\n",
      "    novel_names.append(name)"
     ],
     "language": "python",
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "novel_names = np.asarray(novel_names)"
     ],
     "language": "python",
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "doctopic_orig = doctopic.copy()"
     ],
     "language": "python",
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "num_groups = len(set(novel_names))"
     ],
     "language": "python",
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "doctopic_grouped = np.zeros((num_groups, num_topics))"
     ],
     "language": "python",
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "for i, name in enumerate(sorted(set(novel_names))):\n",
      "    doctopic_grouped[i, :] = np.mean(doctopic[novel_names == name, :], axis=0)"
     ],
     "language": "python",
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "doctopic = doctopic_grouped"
     ],
     "language": "python",
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "array([[ 0.00940137,  0.02198766,  0.06909261,  0.01937236,  0.01721743,\n         0.03939482,  0.04235553,  0.0155304 ,  0.02242753,  0.06397679,\n         0.09820157,  0.06772253,  0.02682038,  0.08408248,  0.01818394,\n         0.02570262,  0.25471202,  0.01920638,  0.01807989,  0.06653169],\n       [ 0.01026464,  0.02834684,  0.05524967,  0.01748529,  0.01391479,\n         0.04653649,  0.04444146,  0.01545923,  0.02156476,  0.06806683,\n         0.11519478,  0.06626382,  0.2492682 ,  0.0851982 ,  0.01889351,\n         0.02501204,  0.01738177,  0.02016548,  0.01874968,  0.06254249],\n       [ 0.00928234,  0.23495008,  0.04877931,  0.02342289,  0.01547125,\n         0.04784639,  0.04277014,  0.01740544,  0.02118801,  0.07534213,\n         0.11940083,  0.06695468,  0.02840345,  0.07347002,  0.01582416,\n         0.02920976,  0.02103474,  0.02070063,  0.01620959,  0.07233415],\n       [ 0.01950465,  0.0158915 ,  0.04176845,  0.09614702,  0.06340653,\n         0.04694648,  0.04586808,  0.02527766,  0.06515124,  0.042326  ,\n         0.03118713,  0.05161013,  0.01789939,  0.03678766,  0.11707202,\n         0.08544288,  0.01560805,  0.07805986,  0.06320325,  0.04084203],\n       [ 0.1104259 ,  0.01539829,  0.0451085 ,  0.05638612,  0.05679139,\n         0.06708179,  0.05056601,  0.02576596,  0.08374916,  0.04175888,\n         0.03500163,  0.04409373,  0.01649369,  0.03824546,  0.03056376,\n         0.06942547,  0.0111799 ,  0.06772526,  0.09172354,  0.04251556]])"
       ],
       "metadata": {}
      }
     ],
     "input": [
      "doctopic[:5]"
     ],
     "language": "python",
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "# doctopic.to_csv('/Users/koitaroh/Documents/GitHub/GeoTweetCollector/data/doctopic.csv', encoding='utf-8')\n",
      "np.savetxt(\"/Users/koitaroh/Documents/GitHub/GeoTweetCollector/data/doctopic.csv\", doctopic, delimiter=\",\")"
     ],
     "language": "python",
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "#inspecting the result\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "CORPUS_PATH_UNSPLIT = os.path.join('data/MalletSampleData', 'austen-brontë-split')"
     ],
     "language": "python",
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "filenames = [os.path.join(CORPUS_PATH_UNSPLIT, fn) for fn in sorted(os.listdir(CORPUS_PATH_UNSPLIT))]"
     ],
     "language": "python",
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "vectorizer = CountVectorizer(input='filename')"
     ],
     "language": "python",
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "dtm = vectorizer.fit_transform(filenames)  # a sparse matrix"
     ],
     "language": "python",
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 41,
       "text": [
        "(813, 22854)"
       ],
       "metadata": {}
      }
     ],
     "input": [
      "dtm.shape"
     ],
     "language": "python",
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 43,
       "text": [
        "2996776"
       ],
       "metadata": {}
      }
     ],
     "input": [
      "dtm.data.nbytes  # number of bytes dtm takes up"
     ],
     "language": "python",
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 46,
       "text": [
        "148642416"
       ],
       "metadata": {}
      }
     ],
     "input": [
      "dtm.toarray().data.nbytes  # number of bytes dtm as array takes up"
     ],
     "language": "python",
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 47,
       "text": [
        "(813, 20)"
       ],
       "metadata": {}
      }
     ],
     "input": [
      "doctopic_orig.shape"
     ],
     "language": "python",
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 49,
       "text": [
        "130080"
       ],
       "metadata": {}
      }
     ],
     "input": [
      "doctopic_orig.data.nbytes  # number of bytes document-topic shares take up"
     ],
     "language": "python",
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "novels = sorted(set(novel_names))"
     ],
     "language": "python",
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Top topics in...\nAusten_Emma: 16 10 13\nAusten_Pride: 12 10 13\nAusten_Sense: 1 10 9\nCBronte_Jane: 14 3 15\nCBronte_Professor: 0 18 8\nCBronte_Villette: 7 4 0\n"
       ]
      }
     ],
     "input": [
      "print(\"Top topics in...\")\n",
      "for i in range(len(doctopic)):\n",
      "    top_topics = np.argsort(doctopic[i,:])[::-1][0:3]\n",
      "    top_topics_str = ' '.join(str(t) for t in top_topics)\n",
      "    print(\"{}: {}\".format(novels[i], top_topics_str))"
     ],
     "language": "python",
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "with open('/tmp/topic-keys-austen-brontë.txt') as input:\n",
      "    topic_keys_lines = input.readlines()"
     ],
     "language": "python",
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "topic_words = []"
     ],
     "language": "python",
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "for line in topic_keys_lines:\n",
      "    _, _, words = line.split('\\t')  # tab-separated\n",
      "    words = words.rstrip().split(' ')  # remove the trailing '\\n'\n",
      "    topic_words.append(words)"
     ],
     "language": "python",
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 61,
       "text": [
        "['madame',\n 'monsieur',\n 'english',\n 'paul',\n 'beck',\n 'de',\n 'pupils',\n 'french',\n 'mademoiselle',\n 'vous',\n 'frances',\n 'mdlle',\n 'est',\n 'pelet',\n 'emanuel',\n 'la',\n 'reuter',\n 'rue',\n 'je']"
       ],
       "metadata": {}
      }
     ],
     "input": [
      "topic_words[0]"
     ],
     "language": "python",
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Topic 0: madame monsieur english paul beck de pupils french mademoiselle vous\nTopic 1: mrs elinor marianne sister mother edward dashwood colonel jennings willoughby\nTopic 2: good man young make world pretty love woman girl people\nTopic 3: heart life god john st love strange mine voice lips\nTopic 4: hand deep held head knew sweet light stood half strong\nTopic 5: thought found time pleasure felt character power sense interest feeling\nTopic 6: made knew thought time point things words gave put taste\nTopic 7: bretton dr thought graham lucy john evening papa child don\nTopic 8: eyes face looked eye hair full sat seat head turned\nTopic 9: man father years life house good wife give woman year\nTopic 10: feelings happiness affection opinion hope present happy regard subject situation\nTopic 11: day morning time return home leave days house place expected\nTopic 12: mr elizabeth darcy jane mrs bennet miss bingley lady sister\nTopic 13: give letter cried till hear heard find word happy replied\nTopic 14: mr sir rochester mrs jane don miss master thought ll\nTopic 15: door room night bed stood hand opened cold turned open\nTopic 16: mr emma mrs miss harriet thing weston knightley elton woodhouse\nTopic 17: long house dark white air high side great lay garden\nTopic 18: day school read work book long hunsden miss called order\nTopic 19: felt mind moment made looked heart friend speak manner wished\n"
       ]
      }
     ],
     "input": [
      "N_WORDS_DISPLAY = 10\n",
      "for t in range(len(topic_words)):\n",
      "    print(\"Topic {}: {}\".format(t, ' '.join(topic_words[t][:N_WORDS_DISPLAY])))"
     ],
     "language": "python",
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "austen_indices, cbronte_indices = [], []"
     ],
     "language": "python",
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "for index, fn in enumerate(sorted(set(novel_names))):\n",
      "    if \"Austen\" in fn:\n",
      "        austen_indices.append(index)\n",
      "    elif \"CBronte\" in fn:\n",
      "        cbronte_indices.append(index)"
     ],
     "language": "python",
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "austen_avg = np.mean(doctopic[austen_indices, :], axis=0)\n",
      "cbronte_avg = np.mean(doctopic[cbronte_indices, :], axis=0)\n",
      "keyness = np.abs(austen_avg - cbronte_avg)\n",
      "ranking = np.argsort(keyness)[::-1]  # from highest to lowest; [::-1] reverses order in Python sequences"
     ],
     "language": "python",
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "ranking[:10]"
     ],
     "language": "python"
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      ""
     ],
     "language": "python"
    }
   ]
  }
 ],
 "cells": [],
 "metadata": {},
 "nbformat": 3,
 "nbformat_minor": 0
}